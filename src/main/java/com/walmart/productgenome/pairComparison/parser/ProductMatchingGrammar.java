/* Generated By:JavaCC: Do not edit this line. ProductMatchingGrammar.java */
package com.walmart.productgenome.pairComparison.parser;
import java.io.*;
import java.util.*;
import com.google.common.collect.*;
import org.apache.commons.collections.*;

import com.walmart.productgenome.pairComparison.model.Constants;
import com.walmart.productgenome.pairComparison.model.rule.*;

public class ProductMatchingGrammar implements ProductMatchingGrammarConstants {
    public static void main(String [] args) throws IOException
    {
        java.io.BufferedReader sr = new java.io.BufferedReader(new java.io.FileReader(args [0]));
        ProductMatchingGrammar parser = new ProductMatchingGrammar(sr);
        try
        {
            System.out.println("Started parsing ..");
            ItemMatchRuleset productMatchingRuleset = parser.getProductMatchingRuleset();
            System.out.println("Successfully finished parsing ..");
            System.out.println("Product Matching Ruleset : " + productMatchingRuleset.toString());
            System.out.println("Expanded rules : \u005cn" + productMatchingRuleset.generateCompleteRules());
        }
        catch (ParseException pe) {
            System.err.println("Failed parsing ..");
            pe.printStackTrace();
        }
    }

// -------------------- PARSER GRAMMAR --------------------------------------------/* Get the ruleset for this grammar*/
  final public ItemMatchRuleset getProductMatchingRuleset() throws ParseException {
    String rulesetName = null;
    Map < String, String > rulesetVarsMap = null;
    Map < String, String > rulesetMetaInfoMap = null;
    Map < String, String > rulesetMetaDefaultsMap = null;
    Map < String, AttributeMatchClause > commonAttrMatchClausesMap = Maps.newHashMap();
    List <ItemMatchRule> definedRules = Lists.newArrayList();
    List < String > includedRuleNames = Lists.newArrayList();
    rulesetMetaDefaultsMap = getRulesetMetaAttributes();
    rulesetVarsMap = getRulesetVariables();
    commonAttrMatchClausesMap = getRulesetCommonClausesMap(rulesetVarsMap, rulesetMetaDefaultsMap);
    definedRules = getRules(rulesetVarsMap, commonAttrMatchClausesMap, rulesetMetaDefaultsMap);
    jj_consume_token(CREATE);
    jj_consume_token(RULESET);
    jj_consume_token(STRING_LITERAL);
            rulesetName = token.image;
    jj_consume_token(AS);
    includedRuleNames = getIncludedRulesInRuleset(definedRules);
    jj_consume_token(END);
    jj_consume_token(0);
        // Only retain the rules that have been included in the ruleset
        List<ItemMatchRule> finalRules = Lists.newArrayList();
        for(ItemMatchRule rule : definedRules)
        {
                        if(includedRuleNames.contains(rule.getRuleName()))
                        {
                                finalRules.add(rule);
                        }
        }

        {if (true) return new ItemMatchRuleset(rulesetName, finalRules);}
    throw new Error("Missing return statement in function");
  }

/* Parse the variables defined for this grammar. These would be replaced inline. */
  final public Map < String, String > getRulesetVariables() throws ParseException {
    Map < String, String > rulesetVarsMap = Maps.newHashMap();
    String varName = null;
    StringBuilder varValue = null;
    label_1:
    while (true) {
      if (jj_2_1(2)) {
        ;
      } else {
        break label_1;
      }
      jj_consume_token(CREATE);
      jj_consume_token(VARIABLE);
      jj_consume_token(STRING_LITERAL);
            varName = token.image;
            varValue = new StringBuilder();
      jj_consume_token(AS);
      label_2:
      while (true) {
        jj_consume_token(STRING_LITERAL);
                varValue.append(token.image);
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case COMMA:
        case OR:
          switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
          case COMMA:
            jj_consume_token(COMMA);
            break;
          case OR:
            jj_consume_token(OR);
            break;
          default:
            jj_la1[0] = jj_gen;
            jj_consume_token(-1);
            throw new ParseException();
          }
          break;
        default:
          jj_la1[1] = jj_gen;
          ;
        }
                if(token.image.equals(","))
                {
                    varValue.append(",");
                }
                else if(token.image.equals("OR"))
                {
                    varValue.append("OR");
                }
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case STRING_LITERAL:
          ;
          break;
        default:
          jj_la1[2] = jj_gen;
          break label_2;
        }
      }
      jj_consume_token(SEMICOLON);
            rulesetVarsMap.put(varName, varValue.toString());
    }
        {if (true) return rulesetVarsMap;}
    throw new Error("Missing return statement in function");
  }

/*
	Parse the common attribute match clauses here. 
*/
  final public Map < String, AttributeMatchClause > getRulesetCommonClausesMap(Map < String, String > rulesetVarsMap, Map<String, String > rulesetMetaDefaultsMap) throws ParseException {
    Map < String, AttributeMatchClause > rulesetCommonClausesMap = Maps.newHashMap();
    String filterClauseName = null;
    AttributeMatchClause commonAttrMatchClause = null;
    label_3:
    while (true) {
      if (jj_2_2(2)) {
        ;
      } else {
        break label_3;
      }
      jj_consume_token(CREATE);
      jj_consume_token(SUBRULE);
      jj_consume_token(STRING_LITERAL);
            filterClauseName = token.image;
      jj_consume_token(AS);
      commonAttrMatchClause = getAttributeMatchClause(rulesetVarsMap, rulesetMetaDefaultsMap);
            rulesetCommonClausesMap.put(filterClauseName, commonAttrMatchClause);
    }
        {if (true) return rulesetCommonClausesMap;}
    throw new Error("Missing return statement in function");
  }

/* Parse the ruleset attributes for this grammar */
  final public Map<String, String > getRulesetMetaAttributes() throws ParseException {
    Map<String, String > rulesetMetaMap = null;
    if (jj_2_3(2)) {
      jj_consume_token(CREATE);
      jj_consume_token(RULESET_ATTRIBUTES);
      jj_consume_token(AS);
      rulesetMetaMap = getAttributeMatchClauseMeta();
      jj_consume_token(END);
    } else {
      ;
    }
        {if (true) return rulesetMetaMap;}
    throw new Error("Missing return statement in function");
  }

/*
	Parses the meta information for the attribute match clause
*/
  final public Map<String, String > getAttributeMatchClauseMeta() throws ParseException {
    Map < String, String > clauseMetaMap = Maps.newHashMap();
    String matcherKey = null;
    String matcherValue = null;
    label_4:
    while (true) {
      matcherKey = parseMatcherMetaKey();
      jj_consume_token(EQUALS);
      matcherValue = parseMatcherMetaValue();
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case SEMICOLON:
        jj_consume_token(SEMICOLON);
        break;
      case AND:
        jj_consume_token(AND);
        break;
      default:
        jj_la1[3] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
            clauseMetaMap.put(matcherKey, matcherValue);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case COMPARER:
      case SOURCE_TOKENIZER:
      case TARGET_TOKENIZER:
      case CONTAINMENT_EVALUATOR:
      case MISSING_ATTRIBUTE_ALLOWED:
      case SCORE_THRESHOLD:
        ;
        break;
      default:
        jj_la1[4] = jj_gen;
        break label_4;
      }
    }
        {if (true) return clauseMetaMap;}
    throw new Error("Missing return statement in function");
  }

/* Parses the matcher domain keywords */
  final public String parseMatcherMetaKey() throws ParseException {
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case COMPARER:
      jj_consume_token(COMPARER);
      break;
    case SOURCE_TOKENIZER:
      jj_consume_token(SOURCE_TOKENIZER);
      break;
    case TARGET_TOKENIZER:
      jj_consume_token(TARGET_TOKENIZER);
      break;
    case CONTAINMENT_EVALUATOR:
      jj_consume_token(CONTAINMENT_EVALUATOR);
      break;
    case MISSING_ATTRIBUTE_ALLOWED:
      jj_consume_token(MISSING_ATTRIBUTE_ALLOWED);
      break;
    case SCORE_THRESHOLD:
      jj_consume_token(SCORE_THRESHOLD);
      break;
    default:
      jj_la1[5] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
        {if (true) return token.image;}
    throw new Error("Missing return statement in function");
  }

/* Parses the matcher domain keyword values */
  final public String parseMatcherMetaValue() throws ParseException {
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case STRING_LITERAL:
      jj_consume_token(STRING_LITERAL);
      break;
    case DECIMAL_FLOATING_POINT_LITERAL:
      jj_consume_token(DECIMAL_FLOATING_POINT_LITERAL);
      break;
    default:
      jj_la1[6] = jj_gen;
      jj_consume_token(-1);
      throw new ParseException();
    }
        {if (true) return token.image;}
    throw new Error("Missing return statement in function");
  }

/* Parse the rules for this grammar */
  final public List < ItemMatchRule > getRules(Map < String, String > attrSetVarsMap, Map < String, AttributeMatchClause > commonAttrMatchClauses, Map<String, String > rulesetMetaDefaultsMap) throws ParseException {
    List < ItemMatchRule > rules = Lists.newArrayList();
    List < AttributeMatchClause > ruleClauses = null;
    List < AttributeMatchClause > rulesetCommonClausesInRule = null;
    ItemMatchRule rule = null;
    AttributeMatchClause ruleClause = null;
    String ruleName = null;
    label_5:
    while (true) {
      jj_consume_token(CREATE);
      jj_consume_token(RULE);
      jj_consume_token(STRING_LITERAL);
            ruleName = token.image;
            ruleClauses = Lists.newArrayList();
      jj_consume_token(AS);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case INCLUDE:
        jj_consume_token(INCLUDE);
        jj_consume_token(SUBRULE);
        jj_consume_token(OPENBRACKET);
        rulesetCommonClausesInRule = getRulesetCommonClausesInRule(commonAttrMatchClauses);
                            if(CollectionUtils.isNotEmpty(rulesetCommonClausesInRule))
                            {
                            ruleClauses.addAll(rulesetCommonClausesInRule);
                            }
        jj_consume_token(CLOSEBRACKET);
        jj_consume_token(SEMICOLON);
        break;
      default:
        jj_la1[7] = jj_gen;
        ;
      }
      label_6:
      while (true) {
        ruleClause = getAttributeMatchClause(attrSetVarsMap, rulesetMetaDefaultsMap);
                ruleClauses.add(ruleClause);
        switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
        case CLAUSE_ATTR_MATCH:
        case BIDIRECTIONAL_MATCH:
        case UNIDIRECTIONAL_MATCH:
          ;
          break;
        default:
          jj_la1[8] = jj_gen;
          break label_6;
        }
      }
      jj_consume_token(END);
            rule = new ItemMatchRule(ruleName, ruleClauses);
            rules.add(rule);
      if (jj_2_4(2)) {
        ;
      } else {
        break label_5;
      }
    }
        {if (true) return rules;}
    throw new Error("Missing return statement in function");
  }

/* Parses the included common rule clauses in rule*/
  final public List < AttributeMatchClause > getRulesetCommonClausesInRule(Map < String, AttributeMatchClause > rulesetCommonClausesMap) throws ParseException {
    List < AttributeMatchClause > rulesetCommonClauses = Lists.newArrayList();
    List < String > commonClauseNames = Lists.newArrayList();
    label_7:
    while (true) {
      jj_consume_token(VARIABLE_IDENTIFIER);
      jj_consume_token(STRING_LITERAL);
            commonClauseNames.add(token.image);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case COMMA:
        jj_consume_token(COMMA);
        break;
      default:
        jj_la1[9] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case VARIABLE_IDENTIFIER:
        ;
        break;
      default:
        jj_la1[10] = jj_gen;
        break label_7;
      }
    }
        for (String commonClauseName : commonClauseNames)
        {
            rulesetCommonClauses.add(rulesetCommonClausesMap.get(commonClauseName));
        }
        {if (true) return rulesetCommonClauses;}
    throw new Error("Missing return statement in function");
  }

/*
	Parses the attribute match clause.
*/
  final public AttributeMatchClause getAttributeMatchClause(Map < String, String > rulesetVarsMap, Map<String, String > rulesetMetaDefaultsMap) throws ParseException {
    AttributeMatchClause attrMatchClause = null;
    List < String > sourceAttrs = null;
    List < String > targetAttrs = null;

    Map<String, String > attrMatchClauseMetaMap = null;
    AttributeMatchClauseMeta attrMatchClauseMeta = null;

    Boolean isBidirectionalMatch = false;
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case BIDIRECTIONAL_MATCH:
    case UNIDIRECTIONAL_MATCH:
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case BIDIRECTIONAL_MATCH:
        jj_consume_token(BIDIRECTIONAL_MATCH);
        break;
      case UNIDIRECTIONAL_MATCH:
        jj_consume_token(UNIDIRECTIONAL_MATCH);
        break;
      default:
        jj_la1[11] = jj_gen;
        jj_consume_token(-1);
        throw new ParseException();
      }
      break;
    default:
      jj_la1[12] = jj_gen;
      ;
    }
                        if (token.image == "BIDIRECTIONAL") {
                                isBidirectionalMatch = true;
                        }
                        else {
                                isBidirectionalMatch = false;
                        }
    jj_consume_token(CLAUSE_ATTR_MATCH);
            sourceAttrs = null;
            targetAttrs = null;
    sourceAttrs = getSourceAttrs(rulesetVarsMap);
    jj_consume_token(IN);
    targetAttrs = getTargetAttrs(rulesetVarsMap);
    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
    case USING:
      jj_consume_token(USING);
      attrMatchClauseMetaMap = getAttributeMatchClauseMeta();
                                // Merge clause attr meta with ruleset defaults, in case of missing entries
                                for(Map.Entry<String, String> entry : rulesetMetaDefaultsMap.entrySet())
                                {
                                        String metaKey = entry.getKey().trim();
                                        String metaValue = entry.getValue().trim();
                                        if(!attrMatchClauseMetaMap.containsKey(metaKey))
                                        {
                                                attrMatchClauseMetaMap.put(metaKey, metaValue);
                                        }
                                        else if(metaKey.equals(Constants.SOURCE_TOKENIZER))
                                        {
                                                // Put a special condition check for target tokenizer here
                                                attrMatchClauseMetaMap.put(Constants.TARGET_TOKENIZER, attrMatchClauseMetaMap.get(Constants.SOURCE_TOKENIZER));
                                        }
                                }

                                // If match direction is explicitly specified, override the default match direction.
                                if(isBidirectionalMatch)
                                {
                                        attrMatchClauseMetaMap.put(Constants.CLAUSE_EVALUATOR, Constants.TWO_WAY_EVALUATOR);
                                }
                                else
                                {
                                        attrMatchClauseMetaMap.put(Constants.CLAUSE_EVALUATOR, Constants.ONE_WAY_EVALUATOR);
                                }
      break;
    default:
      jj_la1[13] = jj_gen;
      ;
    }
                if(attrMatchClauseMetaMap != null)
                {
                        attrMatchClauseMeta = new AttributeMatchClauseMeta(attrMatchClauseMetaMap);
                }
                // if no metadata has been defined for the clause, it inherits the default ruleset metadata.
                else
                {
                        attrMatchClauseMeta = new AttributeMatchClauseMeta(rulesetMetaDefaultsMap);
                }

        attrMatchClause = new AttributeMatchClause(sourceAttrs, targetAttrs, attrMatchClauseMeta);
        {if (true) return attrMatchClause;}
    throw new Error("Missing return statement in function");
  }

/* Gets the source attributes defined in the rule clause.*/
  final public List < String > getSourceAttrs(Map < String, String > attrSetVarsMap) throws ParseException {
    List < String > srcAttrs = Lists.newArrayList();
    boolean isAttrSetVarDefined = false;
    jj_consume_token(OPENBRACKET);
    label_8:
    while (true) {
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case VARIABLE_IDENTIFIER:
        jj_consume_token(VARIABLE_IDENTIFIER);
        break;
      default:
        jj_la1[14] = jj_gen;
        ;
      }
            // Hack. How to handle ()? because if this doesn't match, it uses last token value
            if (token.image == "#")
            {
                isAttrSetVarDefined = true;
            }
      jj_consume_token(STRING_LITERAL);
            // Hack : TODO inline replacement of defined attribute set variables.
            if (isAttrSetVarDefined)
            {
                String srcAttrSetString = attrSetVarsMap.get(token.image);
                String[] srcAttrSet = srcAttrSetString.split("OR");
                for(String srcAttr : srcAttrSet)
                {
                    srcAttrs.add(srcAttr.trim());
                }
            }
            else
            {
                srcAttrs.add(token.image);
            }
            isAttrSetVarDefined = false;
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case OR:
        jj_consume_token(OR);
        break;
      default:
        jj_la1[15] = jj_gen;
        ;
      }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case VARIABLE_IDENTIFIER:
      case STRING_LITERAL:
        ;
        break;
      default:
        jj_la1[16] = jj_gen;
        break label_8;
      }
    }
    jj_consume_token(CLOSEBRACKET);
        {if (true) return srcAttrs;}
    throw new Error("Missing return statement in function");
  }

/* Gets the destination attributes defined in the rule clause. */
  final public List < String > getTargetAttrs(Map < String, String > attrSetVarsMap) throws ParseException {
    List < String > targetAttrs = Lists.newArrayList();
    StringBuilder sb = new StringBuilder();
    boolean isAttrSetVarDefined = false;
    jj_consume_token(OPENBRACKET);
    label_9:
    while (true) {
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case VARIABLE_IDENTIFIER:
        jj_consume_token(VARIABLE_IDENTIFIER);
        break;
      default:
        jj_la1[17] = jj_gen;
        ;
      }
            // Hack. How to handle ()? because if this doesn't match, it uses last token value
            if (token.image == "#")
            {
                isAttrSetVarDefined = true;
            }
      jj_consume_token(STRING_LITERAL);
            // Hack : TODO inline replacement of defined attribute set variables.
            if (isAttrSetVarDefined)
            {
                sb.append(attrSetVarsMap.get(token.image));
            }
            else
            {
                sb.append(token.image);
            }
            isAttrSetVarDefined = false;
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case COMMA:
        jj_consume_token(COMMA);
        break;
      default:
        jj_la1[18] = jj_gen;
        ;
      }
            // TODO : Fix this hack. How to handle ()?
            if (token.image == ",")
            {
                sb.append(token.image);
            }
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case VARIABLE_IDENTIFIER:
      case STRING_LITERAL:
        ;
        break;
      default:
        jj_la1[19] = jj_gen;
        break label_9;
      }
    }
    jj_consume_token(CLOSEBRACKET);
        String [ ] targetAttrsExpandedList = sb.toString().split(",");
        for (String targetAttr : targetAttrsExpandedList)
        {
            targetAttrs.add(targetAttr);
        }
        {if (true) return targetAttrs;}
    throw new Error("Missing return statement in function");
  }

/*
	Parse the included rules in ruleset declaration.
	Do a validation check to ensure that the rules included in the ruleset are defined, else
	throw an exception.
*/
  final public List <String> getIncludedRulesInRuleset(List <ItemMatchRule> definedRules) throws ParseException {
    List < String > rulesToInclude = Lists.newArrayList();
    String ruleName = null;
    label_10:
    while (true) {
      jj_consume_token(INCLUDE);
      jj_consume_token(RULE);
      jj_consume_token(STRING_LITERAL);
            ruleName = token.image;
      jj_consume_token(SEMICOLON);
            rulesToInclude.add(ruleName);
      switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {
      case INCLUDE:
        ;
        break;
      default:
        jj_la1[20] = jj_gen;
        break label_10;
      }
    }
        // Hack : TODO how can I move this validation to outside the grammar code but just before
        // returning the ruleset to the caller function.
        boolean areAllIncludedRulesDefined = true;
        List <String> undefinedRules = Lists.newArrayList();
        for (String includedRuleName : rulesToInclude)
        {
            boolean isCurrIncludedRuleDefined = false;
            for (ItemMatchRule rule : definedRules)
            {
                if (rule.getRuleName().equals(includedRuleName))
                {
                    isCurrIncludedRuleDefined = true;
                    break;
                }
            }
            if (!isCurrIncludedRuleDefined)
            {
                areAllIncludedRulesDefined = false;
                undefinedRules.add(includedRuleName);
            }
        }
        if (!areAllIncludedRulesDefined)
        {
            {if (true) throw new ParseException("Following rules have been included but not defined in the grammar " + undefinedRules.toString());}
        }

        {if (true) return rulesToInclude;}
    throw new Error("Missing return statement in function");
  }

  private boolean jj_2_1(int xla) {
    jj_la = xla; jj_lastpos = jj_scanpos = token;
    try { return !jj_3_1(); }
    catch(LookaheadSuccess ls) { return true; }
    finally { jj_save(0, xla); }
  }

  private boolean jj_2_2(int xla) {
    jj_la = xla; jj_lastpos = jj_scanpos = token;
    try { return !jj_3_2(); }
    catch(LookaheadSuccess ls) { return true; }
    finally { jj_save(1, xla); }
  }

  private boolean jj_2_3(int xla) {
    jj_la = xla; jj_lastpos = jj_scanpos = token;
    try { return !jj_3_3(); }
    catch(LookaheadSuccess ls) { return true; }
    finally { jj_save(2, xla); }
  }

  private boolean jj_2_4(int xla) {
    jj_la = xla; jj_lastpos = jj_scanpos = token;
    try { return !jj_3_4(); }
    catch(LookaheadSuccess ls) { return true; }
    finally { jj_save(3, xla); }
  }

  private boolean jj_3_3() {
    if (jj_scan_token(CREATE)) return true;
    if (jj_scan_token(RULESET_ATTRIBUTES)) return true;
    return false;
  }

  private boolean jj_3_2() {
    if (jj_scan_token(CREATE)) return true;
    if (jj_scan_token(SUBRULE)) return true;
    return false;
  }

  private boolean jj_3_4() {
    if (jj_scan_token(CREATE)) return true;
    if (jj_scan_token(RULE)) return true;
    return false;
  }

  private boolean jj_3_1() {
    if (jj_scan_token(CREATE)) return true;
    if (jj_scan_token(VARIABLE)) return true;
    return false;
  }

  /** Generated Token Manager. */
  public ProductMatchingGrammarTokenManager token_source;
  SimpleCharStream jj_input_stream;
  /** Current token. */
  public Token token;
  /** Next token. */
  public Token jj_nt;
  private int jj_ntk;
  private Token jj_scanpos, jj_lastpos;
  private int jj_la;
  private int jj_gen;
  final private int[] jj_la1 = new int[21];
  static private int[] jj_la1_0;
  static private int[] jj_la1_1;
  static {
      jj_la1_init_0();
      jj_la1_init_1();
   }
   private static void jj_la1_init_0() {
      jj_la1_0 = new int[] {0x2002000,0x2002000,0x0,0x1001000,0x80000000,0x80000000,0x0,0x40000,0x0,0x2000,0x8000000,0x0,0x0,0x800000,0x8000000,0x2000000,0x8000000,0x8000000,0x2000,0x8000000,0x40000,};
   }
   private static void jj_la1_init_1() {
      jj_la1_1 = new int[] {0x0,0x0,0x100,0x0,0x1f,0x1f,0x300,0x0,0xe0,0x0,0x0,0xc0,0xc0,0x0,0x0,0x0,0x100,0x0,0x0,0x100,0x0,};
   }
  final private JJCalls[] jj_2_rtns = new JJCalls[4];
  private boolean jj_rescan = false;
  private int jj_gc = 0;

  /** Constructor with InputStream. */
  public ProductMatchingGrammar(java.io.InputStream stream) {
     this(stream, null);
  }
  /** Constructor with InputStream and supplied encoding */
  public ProductMatchingGrammar(java.io.InputStream stream, String encoding) {
    try { jj_input_stream = new SimpleCharStream(stream, encoding, 1, 1); } catch(java.io.UnsupportedEncodingException e) { throw new RuntimeException(e); }
    token_source = new ProductMatchingGrammarTokenManager(jj_input_stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 21; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  /** Reinitialise. */
  public void ReInit(java.io.InputStream stream) {
     ReInit(stream, null);
  }
  /** Reinitialise. */
  public void ReInit(java.io.InputStream stream, String encoding) {
    try { jj_input_stream.ReInit(stream, encoding, 1, 1); } catch(java.io.UnsupportedEncodingException e) { throw new RuntimeException(e); }
    token_source.ReInit(jj_input_stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 21; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  /** Constructor. */
  public ProductMatchingGrammar(java.io.Reader stream) {
    jj_input_stream = new SimpleCharStream(stream, 1, 1);
    token_source = new ProductMatchingGrammarTokenManager(jj_input_stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 21; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  /** Reinitialise. */
  public void ReInit(java.io.Reader stream) {
    jj_input_stream.ReInit(stream, 1, 1);
    token_source.ReInit(jj_input_stream);
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 21; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  /** Constructor with generated Token Manager. */
  public ProductMatchingGrammar(ProductMatchingGrammarTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 21; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  /** Reinitialise. */
  public void ReInit(ProductMatchingGrammarTokenManager tm) {
    token_source = tm;
    token = new Token();
    jj_ntk = -1;
    jj_gen = 0;
    for (int i = 0; i < 21; i++) jj_la1[i] = -1;
    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();
  }

  private Token jj_consume_token(int kind) throws ParseException {
    Token oldToken;
    if ((oldToken = token).next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    if (token.kind == kind) {
      jj_gen++;
      if (++jj_gc > 100) {
        jj_gc = 0;
        for (int i = 0; i < jj_2_rtns.length; i++) {
          JJCalls c = jj_2_rtns[i];
          while (c != null) {
            if (c.gen < jj_gen) c.first = null;
            c = c.next;
          }
        }
      }
      return token;
    }
    token = oldToken;
    jj_kind = kind;
    throw generateParseException();
  }

  static private final class LookaheadSuccess extends java.lang.Error { }
  final private LookaheadSuccess jj_ls = new LookaheadSuccess();
  private boolean jj_scan_token(int kind) {
    if (jj_scanpos == jj_lastpos) {
      jj_la--;
      if (jj_scanpos.next == null) {
        jj_lastpos = jj_scanpos = jj_scanpos.next = token_source.getNextToken();
      } else {
        jj_lastpos = jj_scanpos = jj_scanpos.next;
      }
    } else {
      jj_scanpos = jj_scanpos.next;
    }
    if (jj_rescan) {
      int i = 0; Token tok = token;
      while (tok != null && tok != jj_scanpos) { i++; tok = tok.next; }
      if (tok != null) jj_add_error_token(kind, i);
    }
    if (jj_scanpos.kind != kind) return true;
    if (jj_la == 0 && jj_scanpos == jj_lastpos) throw jj_ls;
    return false;
  }


/** Get the next Token. */
  final public Token getNextToken() {
    if (token.next != null) token = token.next;
    else token = token.next = token_source.getNextToken();
    jj_ntk = -1;
    jj_gen++;
    return token;
  }

/** Get the specific Token. */
  final public Token getToken(int index) {
    Token t = token;
    for (int i = 0; i < index; i++) {
      if (t.next != null) t = t.next;
      else t = t.next = token_source.getNextToken();
    }
    return t;
  }

  private int jj_ntk() {
    if ((jj_nt=token.next) == null)
      return (jj_ntk = (token.next=token_source.getNextToken()).kind);
    else
      return (jj_ntk = jj_nt.kind);
  }

  private java.util.List<int[]> jj_expentries = new java.util.ArrayList<int[]>();
  private int[] jj_expentry;
  private int jj_kind = -1;
  private int[] jj_lasttokens = new int[100];
  private int jj_endpos;

  private void jj_add_error_token(int kind, int pos) {
    if (pos >= 100) return;
    if (pos == jj_endpos + 1) {
      jj_lasttokens[jj_endpos++] = kind;
    } else if (jj_endpos != 0) {
      jj_expentry = new int[jj_endpos];
      for (int i = 0; i < jj_endpos; i++) {
        jj_expentry[i] = jj_lasttokens[i];
      }
      jj_entries_loop: for (java.util.Iterator<?> it = jj_expentries.iterator(); it.hasNext();) {
        int[] oldentry = (int[])(it.next());
        if (oldentry.length == jj_expentry.length) {
          for (int i = 0; i < jj_expentry.length; i++) {
            if (oldentry[i] != jj_expentry[i]) {
              continue jj_entries_loop;
            }
          }
          jj_expentries.add(jj_expentry);
          break jj_entries_loop;
        }
      }
      if (pos != 0) jj_lasttokens[(jj_endpos = pos) - 1] = kind;
    }
  }

  /** Generate ParseException. */
  public ParseException generateParseException() {
    jj_expentries.clear();
    boolean[] la1tokens = new boolean[42];
    if (jj_kind >= 0) {
      la1tokens[jj_kind] = true;
      jj_kind = -1;
    }
    for (int i = 0; i < 21; i++) {
      if (jj_la1[i] == jj_gen) {
        for (int j = 0; j < 32; j++) {
          if ((jj_la1_0[i] & (1<<j)) != 0) {
            la1tokens[j] = true;
          }
          if ((jj_la1_1[i] & (1<<j)) != 0) {
            la1tokens[32+j] = true;
          }
        }
      }
    }
    for (int i = 0; i < 42; i++) {
      if (la1tokens[i]) {
        jj_expentry = new int[1];
        jj_expentry[0] = i;
        jj_expentries.add(jj_expentry);
      }
    }
    jj_endpos = 0;
    jj_rescan_token();
    jj_add_error_token(0, 0);
    int[][] exptokseq = new int[jj_expentries.size()][];
    for (int i = 0; i < jj_expentries.size(); i++) {
      exptokseq[i] = jj_expentries.get(i);
    }
    return new ParseException(token, exptokseq, tokenImage);
  }

  /** Enable tracing. */
  final public void enable_tracing() {
  }

  /** Disable tracing. */
  final public void disable_tracing() {
  }

  private void jj_rescan_token() {
    jj_rescan = true;
    for (int i = 0; i < 4; i++) {
    try {
      JJCalls p = jj_2_rtns[i];
      do {
        if (p.gen > jj_gen) {
          jj_la = p.arg; jj_lastpos = jj_scanpos = p.first;
          switch (i) {
            case 0: jj_3_1(); break;
            case 1: jj_3_2(); break;
            case 2: jj_3_3(); break;
            case 3: jj_3_4(); break;
          }
        }
        p = p.next;
      } while (p != null);
      } catch(LookaheadSuccess ls) { }
    }
    jj_rescan = false;
  }

  private void jj_save(int index, int xla) {
    JJCalls p = jj_2_rtns[index];
    while (p.gen > jj_gen) {
      if (p.next == null) { p = p.next = new JJCalls(); break; }
      p = p.next;
    }
    p.gen = jj_gen + xla - jj_la; p.first = token; p.arg = xla;
  }

  static final class JJCalls {
    int gen;
    Token first;
    int arg;
    JJCalls next;
  }

}
